import torch
import torch.nn as nn
import torch.optim as optim
from facenet_pytorch import InceptionResnetV1
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import random
import os
from tqdm import tqdm

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• FaceNet (VGGFace2)
model = InceptionResnetV1(pretrained='vggface2', classify=False).train()

# Freeze ‡∏ä‡∏±‡πâ‡∏ô‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô
for name, param in model.named_parameters():
    if 'conv' in name:
        param.requires_grad = False

# ‡πÉ‡∏ä‡πâ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
print(f"Using device: {device}")
print(torch.cuda.is_available())  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ CUDA ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
print(torch.cuda.current_device())  # ‡∏î‡∏π‡∏ß‡πà‡∏≤ GPU ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà
print(torch.cuda.get_device_name(0))  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠ GPU ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

# Loss Function
loss_fn = nn.TripletMarginLoss(margin=1.0)

# Optimizer
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00001)

# ‡πÄ‡∏û‡∏¥‡πà‡∏° Data Augmentation ‡∏£‡∏ß‡∏° Gaussian Blur ‡πÅ‡∏•‡∏∞ Brightness adjustment
transform = transforms.Compose([
    transforms.RandomResizedCrop(160, scale=(0.9, 1.0)),  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î crop ‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),  # ‡πÄ‡∏û‡∏¥‡πà‡∏° Rotation ¬±15¬∞
    transforms.ColorJitter(brightness=0.1, contrast=0.2, saturation=0.2, hue=0.1),  # ‡∏•‡∏î brightness ‡πÄ‡∏õ‡πá‡∏ô 0.1
    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),  # ‡∏•‡∏î blur ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≠‡∏ô‡∏•‡∏á
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x + 0.05 * torch.randn_like(x)),  # Gaussian Noise (‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 0.05 ‚Üí 0.03)
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  
])


dataset = datasets.ImageFolder(root="dataset/train", transform=transform)
dataloader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡∏°‡∏µ checkpoint
checkpoint_path = "facenet_checkpoint.pth"
start_epoch = 0

if os.path.exists(checkpoint_path):
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint["model_state"])
    optimizer.load_state_dict(checkpoint["optimizer_state"])
    start_epoch = checkpoint["epoch"] + 1
    print(f"üîÑ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å '{checkpoint_path}', ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà Epoch {start_epoch}")
else:
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ù‡∏∂‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Triplets
def get_triplets(images, labels):
    anchors, positives, negatives = [], [], []
    unique_labels = list(set(labels.tolist()))

    for label in unique_labels:
        same_class_indices = torch.where(labels == label)[0]
        different_class_indices = torch.where(labels != label)[0]

        if len(same_class_indices) > 1 and len(different_class_indices) > 0:
            try:
                anchor, positive = random.sample(list(same_class_indices), 2)
                negative = random.choice(list(different_class_indices))
                anchors.append(images[anchor])
                positives.append(images[positive])
                negatives.append(images[negative])
            except ValueError:
                continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

    if len(anchors) == 0:
        return None, None, None

    return torch.stack(anchors), torch.stack(positives), torch.stack(negatives)


# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å
def train_model():
    epochs = 50
    global start_epoch  
    best_loss = float('inf')  # ‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£ loss ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    patience = 5 # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏≠‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡∏£ loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á
    trigger_times = 0  # ‡∏ï‡∏±‡∏ß‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á

    for epoch in range(start_epoch, epochs):
        print(f"üü° ‡πÄ‡∏£‡∏¥‡πà‡∏° Epoch {epoch + 1}/{epochs}")

        model.train()
        total_loss = 0

        # ‡πÉ‡∏ä‡πâ tqdm ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á progress bar
        with tqdm(dataloader, desc=f"Epoch {epoch+1}", total=len(dataloader)) as pbar:
            for batch_idx, (images, labels) in enumerate(pbar):
                if len(images) < 2:
                    continue

                optimizer.zero_grad()
                anchors, positives, negatives = get_triplets(images, labels)

                if anchors is None or len(anchors) == 0:
                    continue

                anchors, positives, negatives = anchors.to(device), positives.to(device), negatives.to(device)

                if len(anchors) == 1:
                    model.eval()
                else:
                    model.train()

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Embeddings
                anchor_embeddings = model(anchors)
                positive_embeddings = model(positives)
                negative_embeddings = model(negatives)

                model.train()

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Loss
                loss = loss_fn(anchor_embeddings, positive_embeddings, negative_embeddings)
                loss.backward()
                optimizer.step()

                total_loss += loss.item()

                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï progress bar
                pbar.set_postfix(loss=loss.item())

        print(f"üü¢ Epoch {epoch + 1}/{epochs} ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô - Total Loss: {total_loss:.4f}\n")

        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ loss ‡∏•‡∏î‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if total_loss < best_loss:
            best_loss = total_loss
            trigger_times = 0  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏°‡∏∑‡πà‡∏≠ loss ‡∏•‡∏î‡∏•‡∏á
            # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà loss ‡∏•‡∏î‡∏•‡∏á
            checkpoint = {
                "epoch": epoch,
                "model_state": model.state_dict(),
                "optimizer_state": optimizer.state_dict(),
            }
            torch.save(checkpoint, checkpoint_path)
            print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà '{checkpoint_path}'")
        else:
            trigger_times += 1
            print(f"üî¥ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á‡∏Ç‡∏≠‡∏á loss ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ {trigger_times} epoch")

        # ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡∏£ loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á‡∏†‡∏≤‡∏¢‡πÉ‡∏ô patience epochs ‡∏Å‡πá‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å
        if trigger_times >= patience:
            print("üö® Early stopping ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ epoch")
            break

    print("‚úÖ ‡∏ù‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

train_model()